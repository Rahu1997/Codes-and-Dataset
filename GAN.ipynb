{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QCcA11PlRcT1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape, Input, UpSampling2D, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3zMR7oEDRu6O"
   },
   "outputs": [],
   "source": [
    "# Set the tumor categories\n",
    "tumors = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "\n",
    "# Function to display 5 images from each folder side by side\n",
    "def display_images_from_folders(folder_paths, n=5):\n",
    "    fig, axs = plt.subplots(len(folder_paths), n, figsize=(8, 3))\n",
    "    for i, folder_path in enumerate(folder_paths):\n",
    "        image_files = os.listdir(folder_path)\n",
    "        for j in range(n):\n",
    "            image_path = os.path.join(folder_path, image_files[j])\n",
    "            image = cv2.imread(image_path)\n",
    "            axs[j].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            axs[j].axis('off')\n",
    "            axs[j].set_title(f'{os.path.basename(folder_path)}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_images(dir, title):\n",
    "  folder = dir\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  # Loop through each tumor category\n",
    "  for tumor in tumors:\n",
    "    # Set the path to the tumor category folder\n",
    "    tumor_folder = os.path.join(folder, tumor)\n",
    "\n",
    "    # Display 5 images from the folder\n",
    "    display_images_from_folders([tumor_folder])\n",
    "\n",
    "    # Get the list of image filenames in the folder\n",
    "    image_files = os.listdir(tumor_folder)\n",
    "\n",
    "    # Loop through each image file\n",
    "    for image_file in image_files:\n",
    "        # Read the image\n",
    "        image_path = os.path.join(tumor_folder, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Resize the image to a fixed size (e.g., 48x48 pixels)\n",
    "        resized_image = cv2.resize(image, (48, 48))\n",
    "\n",
    "        # Normalize the image data\n",
    "        normalized_image = resized_image / 255.0\n",
    "\n",
    "        # Append the image data and label to the lists\n",
    "        data.append(normalized_image)\n",
    "        labels.append(tumor)\n",
    "\n",
    "  # Convert the data and labels lists to NumPy arrays\n",
    "  data = np.array(data)\n",
    "  labels = np.array(labels)\n",
    "\n",
    "  # Display the bar chart showing the number of images in each class\n",
    "  num_images_per_class = [len(data[labels == tumor]) for tumor in tumors]\n",
    "  plt.bar(tumors, num_images_per_class)\n",
    "  plt.xlabel('Tumor')\n",
    "  plt.ylabel('Number of Images')\n",
    "  plt.title(f'Images in {title} set')\n",
    "  plt.show()\n",
    "\n",
    "  return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZsTtWgT8RzQr"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/drive/MyDrive/June 2023/Brain Tumor Classification/Training\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mload_images\u001b[1;34m(dir, title)\u001b[0m\n\u001b[0;32m     26\u001b[0m tumor_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder, tumor)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Display 5 images from the folder\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mdisplay_images_from_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtumor_folder\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Get the list of image filenames in the folder\u001b[39;00m\n\u001b[0;32m     32\u001b[0m image_files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(tumor_folder)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mdisplay_images_from_folders\u001b[1;34m(folder_paths, n)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdisplay_images_from_folders\u001b[39m(folder_paths, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;28mlen\u001b[39m(folder_paths), n, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, folder_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(folder_paths):\n\u001b[0;32m      8\u001b[0m         image_files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(folder_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_images('/content/drive/MyDrive/June 2023/Brain Tumor Classification/Training', 'Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOczr8Cqkrc7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1VEynxs1R2HL"
   },
   "outputs": [],
   "source": [
    "X_test, y_test = load_images('/content/drive/MyDrive/June 2023/Brain Tumor Classification/Testing', 'Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJqKHE2wP74z"
   },
   "outputs": [],
   "source": [
    "# Getting the percentage of frequency of classes in training and testing sets\n",
    "f, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "pd.DataFrame(y_train).value_counts().plot.pie(autopct='%1.1f%%',ax=ax[0])\n",
    "ax[0].set_title('Training set: Tumor distribution')\n",
    "pd.DataFrame(y_test).value_counts().plot.pie(autopct='%1.1f%%',ax=ax[1])\n",
    "ax[1].set_title('Testing set: Tumor distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkaxipS0TFDt"
   },
   "source": [
    "### CNN with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Xpm9a7FP0cL"
   },
   "outputs": [],
   "source": [
    "y_train_new = []\n",
    "for i in y_train:\n",
    "    y_train_new.append(tumors.index(i))\n",
    "y_train_1 = y_train_new\n",
    "y_train_1 = tf.keras.utils.to_categorical(y_train_1)\n",
    "\n",
    "\n",
    "y_test_new = []\n",
    "for i in y_test:\n",
    "    y_test_new.append(tumors.index(i))\n",
    "y_test_1 = y_test_new\n",
    "y_test_1 = tf.keras.utils.to_categorical(y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ptEdAwRSAtw"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.figure(figsize = (6,6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    cm = np.round(cm,2)\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BadaVQ7TITW"
   },
   "outputs": [],
   "source": [
    "# Create the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))  # 4 types of brain tumors\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation to improve generalization\n",
    "datagen = ImageDataGenerator(rotation_range=20,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest')\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "history_1 = model.fit(datagen.flow(X_train, y_train_1, batch_size=batch_size),\n",
    "                      steps_per_epoch=len(X_train) / batch_size,\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(X_test, y_test_1))\n",
    "\n",
    "# Model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7I0acc1uVnC1"
   },
   "outputs": [],
   "source": [
    "y_pred_encoded = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_encoded,axis=1)\n",
    "print('Testing accuracy: ', accuracy_score(y_pred, np.argmax(y_test_1, axis=1)))\n",
    "\n",
    "cnn_confusion_mtx = confusion_matrix(np.argmax(y_test_1, axis=1), y_pred)\n",
    "cm = plot_confusion_matrix(cnn_confusion_mtx, classes = tumors, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5kKEcHtTI5X"
   },
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8remaA6KNaSU"
   },
   "outputs": [],
   "source": [
    "width, height, channel = 48, 48, 3\n",
    "\n",
    "def sample_images(generator, noise, subplots, figsize=(22,8), save=False):\n",
    "    generated_images = generator.predict(noise)\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    for i, image in enumerate(generated_images):\n",
    "        plt.subplot(subplots[0], subplots[1], i+1)\n",
    "        if channel == 1:\n",
    "            plt.imshow(image.reshape((width, height)), cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(image.reshape((width, height, channel)))\n",
    "        if save == True:\n",
    "            img_name = \"gen\" + str(i)\n",
    "            plt.savefig(img_name)\n",
    "        plt.subplots_adjust(wspace=None, hspace=None)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwEm_ZyITM6Y"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess your data (assuming X contains the images)\n",
    "# Replace this with your data loading and preprocessing code\n",
    "X = X_train # Shape: (number of records, 48, 48, 3)\n",
    "\n",
    "# Normalize images to the range [-1, 1]\n",
    "X = (X.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "# Define the Generator model\n",
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128 * 12 * 12, input_dim=latent_dim))\n",
    "    model.add(Reshape((12, 12, 128)))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(3, kernel_size=3, padding=\"same\", activation=\"tanh\"))\n",
    "    return model\n",
    "\n",
    "# Define the Discriminator model\n",
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "# Define hyperparameters\n",
    "latent_dim = 100\n",
    "img_shape = (48, 48, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ig2rf0iCk7B"
   },
   "outputs": [],
   "source": [
    "# Build and compile the Discriminator\n",
    "discriminator = build_discriminator(img_shape)\n",
    "discriminator.compile(loss='categorical_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "\n",
    "# Build the Generator\n",
    "generator = build_generator(latent_dim)\n",
    "\n",
    "# The combined GAN model: Generator -> Discriminator\n",
    "z = Input(shape=(latent_dim,))\n",
    "img = generator(z)\n",
    "discriminator.trainable = False\n",
    "validity = discriminator(img)\n",
    "\n",
    "combined = Model(z, validity)\n",
    "combined.compile(loss='categorical_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "\n",
    "# Model summary\n",
    "print(generator.summary())\n",
    "print(discriminator.summary())\n",
    "print(combined.summary())\n",
    "\n",
    "# Training loop\n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "best_acc = 0.8\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Select a random batch of real images\n",
    "    idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "    real_imgs = X[idx]\n",
    "\n",
    "    # Generate a batch of fake images\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    fake_imgs = generator.predict(noise)\n",
    "\n",
    "    # Train the Discriminator\n",
    "    d_loss_real = discriminator.train_on_batch(real_imgs, np.ones((batch_size, 4)))\n",
    "    d_loss_fake = discriminator.train_on_batch(fake_imgs, np.zeros((batch_size, 4)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Train the Generator\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    g_loss = combined.train_on_batch(noise, np.ones((batch_size, 4)))\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch}, Discriminator Loss: {d_loss[0]}, Acc.: {100 * d_loss[1]}, Generator Loss: {g_loss}\")\n",
    "\n",
    "    if d_loss[1] >= best_acc:\n",
    "      print(f\"Reached desired accuracy ({best_acc}), stopping training.\")\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBhq2ZdEWkTI"
   },
   "outputs": [],
   "source": [
    "#Generation\n",
    "noise = np.random.normal(0, 1, size=(100, latent_dim))\n",
    "sample_images(generator, noise, (10,10), (24,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbWtZoqWNUbS"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(10,5))\n",
    "\n",
    "sns.distplot(X_train, label='Real Images', hist=True, color='#fc0328', ax=axs)\n",
    "sns.distplot(fake_imgs, label='Generated Images', hist=True, color='#0c06c7', ax=axs)\n",
    "axs.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yn0DBT6eS0U1"
   },
   "source": [
    "### GAN with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kKrrcvXOF0as"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Build and compile the Generator\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m generator_augment \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_generator\u001b[49m(latent_dim)\n\u001b[0;32m      3\u001b[0m generator_augment\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mAdam(\u001b[38;5;241m0.0002\u001b[39m, \u001b[38;5;241m0.5\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Build and compile the Discriminator\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Build and compile the Generator\n",
    "generator_augment = build_generator(latent_dim)\n",
    "generator_augment.compile(loss='categorical_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "\n",
    "# Build and compile the Discriminator\n",
    "discriminator_augment = build_discriminator(img_shape)\n",
    "discriminator_augment.compile(loss='categorical_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "\n",
    "# The combined GAN model: Generator -> Discriminator\n",
    "z = Input(shape=(latent_dim,))\n",
    "img = generator_augment(z)\n",
    "discriminator_augment.trainable = False\n",
    "validity = discriminator_augment(img)\n",
    "\n",
    "combined_augment = Model(z, validity)\n",
    "combined_augment.compile(loss='categorical_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "\n",
    "# Data augmentation using ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "print(generator_augment.summary())\n",
    "print(discriminator_augment.summary())\n",
    "print(combined_augment.summary())\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Select a batch of real images\n",
    "    idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "    real_imgs = X[idx]\n",
    "\n",
    "    # Generate a batch of fake images\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    fake_imgs = generator_augment.predict(noise)\n",
    "\n",
    "    # Augment the batch of real images\n",
    "    real_imgs_augmented = datagen.flow(real_imgs, batch_size=batch_size, shuffle=False).next()\n",
    "\n",
    "    # Train the Discriminator on real and fake images\n",
    "    real_labels = np.ones((batch_size, 4))\n",
    "    fake_labels = np.zeros((batch_size, 4))\n",
    "    d_loss_real = discriminator_augment.train_on_batch(real_imgs_augmented, real_labels)\n",
    "    d_loss_fake = discriminator_augment.train_on_batch(fake_imgs, fake_labels)\n",
    "\n",
    "    # Train the Generator to fool the Discriminator\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    valid_labels = np.ones((batch_size, 4))\n",
    "    g_loss = combined_augment.train_on_batch(noise, valid_labels)\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch}, D Loss Real: {d_loss_real[0]}, Training Acc.: {100 * d_loss_real[1]}, D Loss Fake: {d_loss_fake[0]}, Testing Acc.: {100 * d_loss_fake[1]}, G Loss: {g_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1Sr02qHb4A7"
   },
   "outputs": [],
   "source": [
    "#Generation\n",
    "noise = np.random.normal(0, 1, size=(100, latent_dim))\n",
    "sample_images(generator_augment, noise, (10,10), (24,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "abPggKWBRwcG"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      3\u001b[0m sns\u001b[38;5;241m.\u001b[39mdistplot(X, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal Images\u001b[39m\u001b[38;5;124m'\u001b[39m, hist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#fc0328\u001b[39m\u001b[38;5;124m'\u001b[39m, ax\u001b[38;5;241m=\u001b[39maxs)\n\u001b[0;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mdistplot(fake_imgs, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerated Images\u001b[39m\u001b[38;5;124m'\u001b[39m, hist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#0c06c7\u001b[39m\u001b[38;5;124m'\u001b[39m, ax\u001b[38;5;241m=\u001b[39maxs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(figsize=(10,5))\n",
    "\n",
    "sns.distplot(X, label='Real Images', hist=True, color='#fc0328', ax=axs)\n",
    "sns.distplot(fake_imgs, label='Generated Images', hist=True, color='#0c06c7', ax=axs)\n",
    "axs.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
